# Stress Detection Project

This project implements a comprehensive deep learning pipeline for detecting stress using physiological signals collected from wearable devices (WESAD and NURSE datasets). It features a modular architecture handling data loading, advanced signal preprocessing, feature extraction, and classification using state-of-the-art neural networks.

## ğŸš€ Key Features

*   **Multi-Modal Data Fusion:** Integrates data from chest (ECG, EDA, EMG, ACC, Temp) and wrist (BVP, EDA, ACC, Temp) devices.
*   **Advanced Models:**
    *   **StressCNNLSTM:** Hybrid architecture combining 1D-CNNs for local feature extraction, Bi-LSTMs for temporal dynamics, and Attention mechanisms.
    *   **StressTransformer:** Transformer-based encoder for capturing long-range dependencies.
    *   **StressLSTM:** Baseline architecture with late fusion.
*   **Robust Preprocessing:**
    *   Automatic signal resampling and alignment.
    *   **Bio-signal Analysis:** Computes HRV (Heart Rate Variability), EDA (Phasic/Tonic), and statistical features using `neurokit2` and `scikit-learn`.
    *   **Parallel Processing:** Optimized feature extraction using `joblib`.
*   **Imbalance Handling:** Implements **SMOTE** (Synthetic Minority Over-sampling Technique) and **Focal Loss** / Class Weighting to address severe class imbalance.
*   **Optimized Pipeline:**
    *   **Hyperparameter Tuning:** Integrated Optuna tuning loop.
    *   **Modular Design:** Separated concerns for loading, splitting, sampling, and training.
    *   **Interactive Visualization:** Jupyter widgets for exploring raw signals, predictions, and model performance.

## ğŸ“‚ Project Structure

```text
C:\Users\bhara\Downloads\Code\StressProject\
â”œâ”€â”€ run_pipeline.py                 # ğŸš€ MAIN ENTRY POINT: Runs the full end-to-end pipeline
â”œâ”€â”€ config.json                     # Central configuration for paths, models, and training
â”œâ”€â”€ requirements.txt                # Project dependencies
â”‚
â”œâ”€â”€ data_loader.py                  # Loads raw WESAD/NURSE data
â”œâ”€â”€ preprocessing.py                # Signal resampling, alignment, and feature extraction orchestration
â”œâ”€â”€ signal_processing.py            # Low-level signal resampling logic
â”œâ”€â”€ feature_extraction.py           # Computation of static features (HRV, EDA peaks, etc.)
â”‚
â”œâ”€â”€ data_pipeline.py                # Pipeline orchestration: windowing, splitting, sampling, dataloaders
â”œâ”€â”€ windowing.py                    # Splits signals into overlapping windows
â”œâ”€â”€ data_splitting.py               # Group-stratified train/val/test splitting
â”œâ”€â”€ sampling.py                     # Handles class imbalance (SMOTE, Random Oversampling)
â”œâ”€â”€ pytorch_datasets.py             # Custom PyTorch Dataset and DataLoader creation
â”‚
â”œâ”€â”€ models.py                       # PyTorch model definitions (LSTM, CNN-LSTM, Transformer)
â”œâ”€â”€ losses.py                       # Custom loss functions (FocalLoss)
â”œâ”€â”€ training.py                     # Training loops, validation, and early stopping
â”œâ”€â”€ evaluation.py                   # Metrics (F1, AUC), threshold optimization, and reporting
â”œâ”€â”€ tuning.py                       # Optuna hyperparameter optimization script
â”‚
â”œâ”€â”€ visualization.py                # Plotting utilities (Signal, ROC, Confusion Matrix)
â”œâ”€â”€ widget_setup.py                 # Interactive Jupyter widgets
â”œâ”€â”€ utils.py                        # Helpers for config, logging, and I/O
â”‚
â””â”€â”€ outputs/                        # Generated artifacts
    â”œâ”€â”€ models/                     # Saved model weights (.pth)
    â”œâ”€â”€ processed_data/             # Cached preprocessed data (.joblib)
    â””â”€â”€ results/                    # Evaluation metrics (.json) and plots (.png)
```

## ğŸ› ï¸ Installation

1.  **Clone the repository:**
    ```bash
    git clone https://github.com/bharathvbcr/Stress_Project.git
    cd StressProject
    ```

2.  **Install Dependencies:**
    It is recommended to use a virtual environment.
    ```bash
    pip install -r requirements.txt
    ```
    *Key libraries: `torch`, `numpy`, `pandas`, `neurokit2`, `scikit-learn`, `optuna`, `shap`, `joblib`.*

## âš™ï¸ Configuration

The `config.json` file controls the entire pipeline. Key sections:

*   **`datasets`**: Paths to WESAD/NURSE data. **Update the `path` values to match your local system.**
*   **`features_to_use`**: Define which sensor channels to use (e.g., `["ECG", "EDA"]`).
*   **`static_features_to_use`**: List of computed features to include (HRV, statistical moments).
*   **`windowing`**: Set `window_size_sec` (default 60s) and `window_overlap` (default 0.5).
*   **`model_config`**: Select model `type` (`CNN-LSTM`, `TRANSFORMER`, `LSTM`) and architecture parameters.
*   **`training_config`**: Hyperparameters (LR, Batch Size, Epochs) and `sampling_strategy` (`smote` or `random`).

## ğŸš€ Usage

### 1. Run the Full Pipeline
The easiest way to run the project is via the main script. This handles data loading, processing, training, and evaluation in one go.

```bash
python run_pipeline.py
```
*Check the console output for detailed logs regarding data loading status, split sizes, and training progress.*

### 2. Hyperparameter Tuning
To optimize model performance using Optuna:

```bash
python tuning.py
```
*This will run multiple trials to find the best hyperparameters (learning rate, layers, etc.) and save them to `outputs/results/best_hyperparameters.json`.*

### 3. Interactive Notebook
For exploration and visualization, use the Jupyter Notebook:
`Baseline_Calibration_for_Stress_Response.ipynb`

*   **Interactive Plots:** Visualize raw signals vs. resampled signals.
*   **Prediction Analysis:** Overlay model predictions on true signal labels.
*   **HRV Analysis:** Inspect ECG signals with detected R-peaks.

## ğŸ“Š Pipeline Stages

1.  **Data Loading:** Reads raw pickle/CSV files.
2.  **Preprocessing:**
    *   **Resampling:** Downsamples signals to a common target rate (e.g., 64Hz).
    *   **Feature Extraction:** Calculates HRV metrics using original high-freq ECG data.
3.  **Windowing:** Slices continuous signals into fixed-length windows (e.g., 60s).
4.  **Splitting:** Performs **Subject-Group Stratified Split** to ensure no subject leakage between Train/Val/Test.
5.  **Sampling:** Applies **SMOTE** or Random Oversampling to the Training set to balance stress/non-stress classes.
6.  **Training:** Trains the PyTorch model with **Early Stopping** and **ReduceLROnPlateau**.
7.  **Evaluation:** Computes Accuracy, F1-Score, Precision, Recall, and ROC-AUC on the Test set. Optimizes the decision threshold for maximum F1.

## ğŸ“ˆ Outputs

Artifacts are saved in the `outputs/` directory:
*   `processed_aligned_data.joblib`: Cached processed signals.
*   `static_features_results.joblib`: Cached feature dataframes.
*   `best_model.pth`: State dictionary of the best trained model.
*   `results/`: Contains:
    *   `test_evaluation_results.json`: Full metrics report.
    *   `confusion_matrix_test.png`: Visual confusion matrix.
    *   `roc_curve_test.png`: ROC Curve.
    *   `training_history.png`: Loss and F1 score curves.